{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding patrons for making possible statments users will write to chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['short','long','old','recent','local','foregin','action',\n",
    "       'anime', 'classic', 'comedy', 'documental', 'drama', 'family',\n",
    "       'fantasy', 'lgbt', 'music', 'religion', 'romance', 'show',\n",
    "       'sports', 'suspense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from movies categories we have categories = ['short','long','old','recent','local','foregin','action',\n",
    "       'anime', 'classic', 'comedy', 'documental', 'drama', 'family',\n",
    "       'fantasy', 'foregin', 'lgbt', 'music', 'religion', 'romance', 'show',\n",
    "       'sports', 'suspense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "say_hello = ['hi','hey!','hello','nice to meet you','how your doing','how is it going']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modals = ['could you','would you','can you','will you','would you mind to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = ['i need','i want','id like','i wanna','im in the mood for','im lookin for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_request = ['recommend me','please make me a recommendation for','give me','pass me','gimme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliars = ['something','some','any','anything']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keywords for categories classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'anime',\n",
       " 'classic',\n",
       " 'comedy',\n",
       " 'documental',\n",
       " 'drama',\n",
       " 'family',\n",
       " 'fantasy',\n",
       " 'lgbt',\n",
       " 'music',\n",
       " 'religion',\n",
       " 'romance',\n",
       " 'show',\n",
       " 'sports',\n",
       " 'suspense']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_keywords = {\n",
    "    'short': [\"Quick\", \"Brief\", \"not long\", \"Concise\", \"Compact\", \"Summarized\", \"Pithy\", \"Short-form\", \"Swift\", \"short\"],\n",
    "    'long': [\"Extended\", \"Lengthy\", \"Comprehensive\", \"long\", \"In-depth\", \"Detailed\", \"Expansive\", \"Extensive\", \"Prolonged\", \"Lengthened\"],\n",
    "    'old': [\"Vintage\", \"Classic\", \"Retro\", \"Antique\", \"Historic\", \"Timeless\", \"Iconic\", \"old\", \"Golden-age\", \"Aged\"],\n",
    "    'recent': [\"Recent\", \"New\", \"Modern\", \"Contemporary\", \"Fresh\", \"Latest\", \"Current\", \"Up-to-date\", \"Newly-released\", \"Recent-release\"],\n",
    "    'local': [\"Local\", \"Regional\", \"Native\", \"Community\", \"Domestic\", \"Hometown\", \"Provincial\", \"Homegrown\", \"Neighborhood\", \"Indigenous\"],\n",
    "    'foregin': [\"Foreign\", \"International\", \"Global\", \"Overseas\", \"Exotic\", \"Imported\", \"Non-native\", \"Alien\", \"Extraterritorial\", \"Exogenous\"],\n",
    "    'action': [\"Action\", \"Thrilling\", \"Adrenaline\", \"Exciting\", \"Intense\", \"Fast-paced\", \"Gritty\", \"Explosive\", \"Stunt-filled\", \"Dynamic\"],\n",
    "    'anime': [\"Anime\", \"Animated\", \"Cartoon\", \"Animation\", \"Manga\", \"Japanese\", \"Animated-series\", \"Otaku\", \"Anime-film\", \"Anime-series\"],\n",
    "    'classic': [\"Classic\", \"Vintage\", \"Iconic\", \"Timeless\", \"Golden-age\", \"Historic\", \"Legendary\", \"Old-school\", \"Traditional\", \"Cinematic\"],\n",
    "    'comedy': [\"Comedy\", \"Funny\", \"Humorous\", \"Hilarious\", \"Light-hearted\", \"Witty\", \"Satirical\", \"Laugh-out-loud\", \"Amusing\", \"Entertaining\"],\n",
    "    'documental': [\"Documentary\", \"Factual\", \"Informative\", \"Educational\", \"realistic\", \"True-story\", \"Real-life\", \"Expository\", \"Investigative\", \"Historical\"],\n",
    "    'drama': [\"Drama\", \"Emotional\", \"Intense\", \"Gripping\", \"Heart-wrenching\", \"Serious\", \"Poignant\", \"Compelling\", \"Powerful\", \"Moving\"],\n",
    "    'family': [\"Family\", \"Kid-friendly\", \"Children\", \"Wholesome\", \"All-ages\", \"Parental\", \"Feel-good\", \"Heartwarming\", \"Adventurous\", \"Animated\"],\n",
    "    'fantasy': [\"Fantasy\", \"Magical\", \"Whimsical\", \"Enchanting\", \"Epic\", \"Mythical\", \"Imaginary\", \"Fairy-tale\", \"Otherworldly\", \"Supernatural\"],\n",
    "    'lgbt': [\"LGBT\", \"Queer\", \"Gay\", \"Lesbian\", \"Transgender\", \"Inclusive\", \"Diverse\", \"Pride\", \"Rainbow\", \"Equality\"],\n",
    "    'music': [\"Music\", \"Musical\", \"Melodious\", \"Rhythmic\", \"Tuneful\", \"Harmonious\", \"Singing\", \"Instrumental\", \"Concert\", \"Rock\"],\n",
    "    'religion': [\"Religion\", \"Spiritual\", \"Faith-based\", \"Sacred\", \"Divine\", \"Inspirational\", \"Theological\", \"Devotional\", \"Cultural\", \"Ritual\"],\n",
    "    'romance': [\"Romance\", \"Love\", \"Love-story\", \"Heartfelt\", \"Passionate\", \"Affectionate\", \"Sentimental\", \"Intimate\", \"Tender\", \"Charming\"],\n",
    "    'show': [\"Show\", \"Series\", \"TV\", \"Television\", \"Binge-worthy\", \"Episodic\", \"Serial\", \"Entertainment\", \"Program\", \"Stream\"],\n",
    "    'sports': [\"Sports\", \"Athletic\", \"Sporting\", \"Competitive\", \"Physical\", \"Games\", \"Team\", \"Athlete\", \"Olympics\", \"Fitness\"],\n",
    "    'suspense': [\"Suspense\", \"Thriller\", \"Mystery\", \"Tense\", \"Nail-biting\", \"Intriguing\", \"Edge-of-your-seat\", \"Puzzling\", \"Gripping\", \"Taut\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build statments for each category :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def make_statments(categories:list,number_stats:int,keywords:dict,random_state):\n",
    "    import random\n",
    "    random.seed(42)\n",
    "    statments = pd.DataFrame()\n",
    "    df_final = pd.DataFrame()\n",
    "   \n",
    "    for category in categories:\n",
    "        stat_list = []\n",
    "        target_list = []\n",
    "        for i in range(0,number_stats):\n",
    "            statm = str(random.choice(say_hello)+' '+random.choice(request)+' '+random.choice(auxiliars)+' ' +random.choice(keywords[category]))\n",
    "            stat_list.append(statm)\n",
    "            target_list.append(category)\n",
    "        statments['text'] = stat_list\n",
    "        statments['target'] = target_list\n",
    "        df_final= pd.concat([df_final,statments],ignore_index=True)\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how is it going i need something Compact</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey! i want some Brief</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how is it going im lookin for something short</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nice to meet you i need something Brief</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hey! i want something Swift</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>nice to meet you i want any Taut</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>how is it going im lookin for anything Thriller</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>hi i wanna some Intriguing</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>how is it going i wanna some Edge-of-your-seat</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>how is it going i wanna any Thriller</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text    target\n",
       "0            how is it going i need something Compact     short\n",
       "1                              hey! i want some Brief     short\n",
       "2       how is it going im lookin for something short     short\n",
       "3             nice to meet you i need something Brief     short\n",
       "4                         hey! i want something Swift     short\n",
       "...                                               ...       ...\n",
       "2095                 nice to meet you i want any Taut  suspense\n",
       "2096  how is it going im lookin for anything Thriller  suspense\n",
       "2097                       hi i wanna some Intriguing  suspense\n",
       "2098   how is it going i wanna some Edge-of-your-seat  suspense\n",
       "2099             how is it going i wanna any Thriller  suspense\n",
       "\n",
       "[2100 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_statments(categories=categories,number_stats=100,keywords=categories_keywords,random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning modelo for multinomial logistic regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=2200,lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = cv.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['action', 'adrenaline', 'adventurous', 'affectionate', 'age',\n",
       "       'aged', 'ages', 'alien', 'all', 'amusing', 'animated', 'animation',\n",
       "       'anime', 'antique', 'any', 'anything', 'athlete', 'athletic',\n",
       "       'based', 'binge', 'biting', 'brief', 'cartoon', 'charming',\n",
       "       'children', 'cinematic', 'classic', 'comedy', 'community',\n",
       "       'compact', 'compelling', 'competitive', 'comprehensive', 'concert',\n",
       "       'concise', 'contemporary', 'cultural', 'current', 'date', 'depth',\n",
       "       'detailed', 'devotional', 'diverse', 'divine', 'documentary',\n",
       "       'doing', 'domestic', 'drama', 'dynamic', 'edge', 'educational',\n",
       "       'emotional', 'enchanting', 'entertaining', 'entertainment', 'epic',\n",
       "       'episodic', 'equality', 'exciting', 'exogenous', 'exotic',\n",
       "       'expansive', 'explosive', 'expository', 'extended', 'extensive',\n",
       "       'extraterritorial', 'factual', 'fairy', 'faith', 'family',\n",
       "       'fantasy', 'fast', 'feel', 'filled', 'film', 'fitness', 'for',\n",
       "       'foreign', 'form', 'fresh', 'friendly', 'funny', 'games', 'gay',\n",
       "       'global', 'going', 'golden', 'good', 'gripping', 'gritty',\n",
       "       'harmonious', 'heart', 'hearted', 'heartfelt', 'heartwarming',\n",
       "       'hello', 'hey', 'hi', 'hilarious', 'historic', 'historical',\n",
       "       'homegrown', 'hometown', 'how', 'humorous', 'iconic', 'id', 'im',\n",
       "       'imaginary', 'imported', 'in', 'inclusive', 'indigenous',\n",
       "       'informative', 'inspirational', 'instrumental', 'intense',\n",
       "       'international', 'intimate', 'intriguing', 'investigative', 'is',\n",
       "       'it', 'japanese', 'kid', 'latest', 'laugh', 'legendary',\n",
       "       'lengthened', 'lengthy', 'lesbian', 'lgbt', 'life', 'light',\n",
       "       'like', 'local', 'long', 'lookin', 'loud', 'love', 'magical',\n",
       "       'manga', 'meet', 'melodious', 'modern', 'mood', 'moving', 'music',\n",
       "       'musical', 'mystery', 'mythical', 'nail', 'native', 'need',\n",
       "       'neighborhood', 'new', 'newly', 'nice', 'non', 'not', 'of', 'old',\n",
       "       'olympics', 'otaku', 'otherworldly', 'out', 'overseas', 'paced',\n",
       "       'parental', 'passionate', 'physical', 'pithy', 'poignant',\n",
       "       'powerful', 'pride', 'program', 'prolonged', 'provincial',\n",
       "       'puzzling', 'queer', 'quick', 'rainbow', 'real', 'realistic',\n",
       "       'recent', 'regional', 'release', 'released', 'religion', 'retro',\n",
       "       'rhythmic', 'ritual', 'rock', 'romance', 'sacred', 'satirical',\n",
       "       'school', 'seat', 'sentimental', 'serial', 'series', 'serious',\n",
       "       'short', 'show', 'singing', 'some', 'something', 'spiritual',\n",
       "       'sporting', 'sports', 'story', 'stream', 'stunt', 'summarized',\n",
       "       'supernatural', 'suspense', 'swift', 'tale', 'taut', 'team',\n",
       "       'television', 'tender', 'tense', 'the', 'theological', 'thriller',\n",
       "       'thrilling', 'timeless', 'to', 'traditional', 'transgender',\n",
       "       'true', 'tuneful', 'tv', 'up', 'vintage', 'wanna', 'want',\n",
       "       'whimsical', 'wholesome', 'witty', 'worthy', 'wrenching', 'you',\n",
       "       'your'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cv,open('../english_version/objects/vectorizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn .model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values\n",
    "x = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]),\n",
       " 'short')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoder = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]),\n",
       " 'short')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2100,), (2100, 246))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action',\n",
       " 'anime',\n",
       " 'classic',\n",
       " 'comedy',\n",
       " 'documental',\n",
       " 'drama',\n",
       " 'family',\n",
       " 'fantasy',\n",
       " 'foregin',\n",
       " 'lgbt',\n",
       " 'local',\n",
       " 'long',\n",
       " 'music',\n",
       " 'old',\n",
       " 'recent',\n",
       " 'religion',\n",
       " 'romance',\n",
       " 'short',\n",
       " 'show',\n",
       " 'sports',\n",
       " 'suspense'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    \n",
       "action        100\n",
       "long          100\n",
       "sports        100\n",
       "show          100\n",
       "short         100\n",
       "romance       100\n",
       "religion      100\n",
       "recent        100\n",
       "old           100\n",
       "music         100\n",
       "local         100\n",
       "anime         100\n",
       "lgbt          100\n",
       "foregin       100\n",
       "fantasy       100\n",
       "family        100\n",
       "drama         100\n",
       "documental    100\n",
       "comedy        100\n",
       "classic       100\n",
       "suspense      100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'target':y}).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(multi_class='multinomial',solver='saga',penalty='l2',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoder, test_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ackerman/anaconda3/envs/chatbot_nltk/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9561904761904761\n",
      "[[23  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 17  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 32  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 33  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 31  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 31  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 24]]\n"
     ]
    }
   ],
   "source": [
    "log_reg.fit(x_train,y_train)\n",
    "pred = log_reg.predict(x_test)\n",
    "print(accuracy_score(y_test,pred))\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#accuracy de 96% not that bad but, lets prove this model with data generated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def make_statments(categories:list,number_stats:int,keywords:dict,random_state:int):\n",
    "    import random\n",
    "    random.seed(random_state)\n",
    "    statments = pd.DataFrame()\n",
    "    df_final = pd.DataFrame()\n",
    "   \n",
    "    for category in categories:\n",
    "        stat_list = []\n",
    "        target_list = []\n",
    "        for i in range(0,number_stats):\n",
    "            statm = str(random.choice(say_hello)+' '+random.choice(modals)+' '+random.choice(make_request)+' '+random.choice(auxiliars)+' ' +random.choice(keywords[category]))\n",
    "            stat_list.append(statm)\n",
    "            target_list.append(category)\n",
    "        statments['text'] = stat_list\n",
    "        statments['target'] = target_list\n",
    "        df_final= pd.concat([df_final,statments],ignore_index=True)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice to meet you will you recommend me any Swift</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nice to meet you will you give me anything Sum...</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how your doing would you gimme some Compact</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hey! could you gimme any Swift</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how is it going would you mind to please make ...</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>hello could you pass me any Tense</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>nice to meet you will you give me anything Mys...</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>how your doing will you give me some Suspense</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>hey! can you give me something Suspense</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>nice to meet you can you give me some Intriguing</td>\n",
       "      <td>suspense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text    target\n",
       "0     nice to meet you will you recommend me any Swift     short\n",
       "1    nice to meet you will you give me anything Sum...     short\n",
       "2          how your doing would you gimme some Compact     short\n",
       "3                       hey! could you gimme any Swift     short\n",
       "4    how is it going would you mind to please make ...     short\n",
       "..                                                 ...       ...\n",
       "625                  hello could you pass me any Tense  suspense\n",
       "626  nice to meet you will you give me anything Mys...  suspense\n",
       "627      how your doing will you give me some Suspense  suspense\n",
       "628            hey! can you give me something Suspense  suspense\n",
       "629   nice to meet you can you give me some Intriguing  suspense\n",
       "\n",
       "[630 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prueba = make_statments(categories=categories,number_stats=30,keywords=categories_keywords,random_state=0)\n",
    "df_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_test(cv,encpder_model,random_state,regresion_model):\n",
    "    df_prueba = make_statments(categories=categories,number_stats=100,keywords=categories_keywords,random_state=random_state)\n",
    "    x = cv.transform(df_prueba['text']).toarray()\n",
    "    print(x)\n",
    "    y = df_prueba['target'].values\n",
    "    print(y.shape)\n",
    "    y_encoded = encpder_model.transform(y)\n",
    "    print(set(y_encoded))\n",
    "    \n",
    "    prediction = regresion_model.predict(x)\n",
    "    print(prediction)\n",
    "    print(accuracy_score(y_encoded,prediction))\n",
    "    print(confusion_matrix(y_encoded,prediction))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 2 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 1 1]\n",
      " [0 0 0 ... 0 1 1]]\n",
      "(2100,)\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}\n",
      "[17 17 17 ...  5 20 20]\n",
      "0.9533333333333334\n",
      "[[ 90   0   0   0   0  10   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0  91   0   0   0   0   9   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0  82   0   0   0   0   0   0   0   0   0   0  18   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0  94   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   6]\n",
      " [  0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0  51   0   0   0   0   0   0   0   0   0   0  49   0   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100   0\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100\n",
      "    0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  100   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 100   0]\n",
      " [  0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  96]]\n"
     ]
    }
   ],
   "source": [
    "get_predictions_test(cv=cv,encpder_model=encoder,random_state=0,regresion_model=log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we got 96% accuracy for new data generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def prediction():    \n",
    "    text = input('')\n",
    "    text = text.lower()\n",
    "    matrix = cv.transform([text]).toarray()\n",
    "    matrix = np.squeeze(matrix)\n",
    "    prediction = log_reg.predict(matrix.reshape(1,-1))\n",
    "    print(log_reg.predict_proba(matrix.reshape(1,-1))*100)\n",
    "    print(text,encoder.inverse_transform(prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(encoder,open('../english_version/objects/encoder.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../english_version/models/english_model.joblib']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(log_reg,'../english_version/models/english_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
